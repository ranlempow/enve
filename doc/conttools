#!/usr/bin/env bash
set -euo pipefail

#  Lightweight process group container


# [chroot, mount, runuser, unshare, nsenter, setpriv, enve]
# ip netns
# lvm
# mount


x='

# 生命週期分為三個階段

1. 建立與部屬前段 - 需要本機root登入
2. 部署後段 - 只需要登入容器內即可執行
3. 執行 - 啟動容器

如果重新部署, 則容器視情況而部分或全部重新啟動

Ship (出貨)
Shipping is your team’s process of getting a snapshot of your service’s code — a version

Deploy (部署)
Deployment is your team’s process for installing the new version of your service’s code on production infrastructure.
(Deployment need not expose customers to a new version of your service.)

Release (發行)
releasing is the process of moving production traffic to the new version.

Rollback (回滾, 重發行)
Rollback is the process of getting production back to a known state, typically by re-releasing the most recent version.


對於非nix儲存但是具有快取唯讀性質的儲存, 一樣採用bindmount的方式綁定到容器中
因此新部署與回滾的速度都會很快, 因為大量的使用之前的部屬的內容, 並且體積也可以縮到最小
目前希望的部署捆綁包要小於500k, 不重複部署小於5M

由於部署又小又快, 因此可以大量嘗試部署, 每天可部署達到500次而不會造成伺服器負擔


網域容器因為含有網路設定以及負載平衡器, 全部重新部署會造成全部服務重新啟動, 網路也會更換, 會斷網1~5分鐘左右
對於網域部署, 如果要不重新啟動容器, 則要採用熱部署, 方法如下:

1. 將部署檔案(通常是設定檔)上傳到容器中的部署庫(可以是git)
2. 在映像庫中建立新的映像資料夾, 執行部屬檔, 建造並部署到新的映像資料夾
3. 這個部署的過程可能會需要把一些data資料夾bind到映像資料夾裡面
4. 解除之前檔案系統的bind或是symlink
5. 將新的映像資料夾bind或是symlink到指定的位置, 並且把這些bind, symlink記錄下來
6. 重新啟動受影響的服務, 可以傳送SIGHUB, 或是手動restart


服務容器可以採用多重部署, 也就是同一套軟體部署了兩個版本以上,
概念是, 概念是對軟體產生別名, 負載平衡器可以自動辨別而且自動載入,
不同的實體指派不同的資源, 通常只有接近無狀態的服務可以如此.

[d]/var/fs/by-label/xxxx
[d]/var/deployrepo(git)/serviceA
[d]/var/imgstore/images-xxxx
[d]/var/imgstore/serviceA-v1.0-inst1[s]/var/...
[d]/var/imgstore/serviceA-v1.0-inst2[s]/var/...
[d]/var/imgstore/serviceA-v1.1[s]/var/...
[d]/var/imgstore/serviceB-v2.0[s]/var/...
[d]/var/imgstore/images-xxxx/serviceA-1 -> [d]/var/imgstore/serviceA-v1.0-inst1
[d]/var/imgstore/images-xxxx/serviceA-2 -> [d]/var/imgstore/serviceA-v1.0-inst2
[d]/var/images -> [d]/var/imgstore/images-xxxx
[d]/etc -> [d]/var/imgstore/etc-xxxx





# 將操作分為幾個時期

pre_setpriv     在拋棄權限前的操作, 這個部分在理想上並不需要
pre_unshare     在產生命名空間前的操作
                例如區塊操作(如lvm)與掛載
                與外部網路連接的操作也在這個時期進行
unshare         已經產生命名空間了, 但是還沒有進入之前的操作
enterns         在進入chroot的前但是已經在命名空間時的操作
chroot          進入chroot之前還保留身分與權限時的操作
                執行enve部署
                部署秘密
                建立服務容器
                例如執行monit以及旗下的sshd
runuser         最終使用型態


建立基本的chroot檔案系統, 不太確定需要放在哪個時期


# 在 linux 使用 tini
https://github.com/krallin/tini



# nix

a = runCommand "a" {
    xxx = [ (import /nix/store/xd4d95w68z45czjwrx210aw1mxg6lnm8-dummy.drv) ];
} ''mkdir -p $out; ln -s /nix/store/5zybyx1h1d74qzavlfpaqcxdzkl3j0w4-dummy/bin/bash $out/x ''


把部署分成兩種類型
1. chroot類: 把所有的依賴都裝在根目錄 "/" 內, 然後靠unix $PATH 來尋找到彼此
2. nix類: 依賴以絕對路徑寫在執行檔內

chroot類是傳統的unix方式, 行之有年, 最流行也是預設的建造模式
chroot類依靠各linux發佈的套件管理來建造與解決依賴, 虛擬化部署的代表是docker

nix類依靠nix來建造與解決依賴, 一般來說.nix檔案比PKGBUILD小很多
但是由於要patch依賴的絕對路徑, 所以仍然會增加維護負擔
config更加困難, 寫死路徑的話就不能熱更新或是動態設定


折衷的辦法是把nix類和chroot類稍微混合
一樣建造一個fakeroot,
然後把部署的nix/store/.../bin等等綁定到fakeroot/bin
nix/store綁定到fakeroot/nix/store
而 nix/store/.../etc/* 則複製到 fakeroot/etc/* 或是符號鏈結
fakeroot/var 則維持正常狀態
fakeroot/home/daemon 也維持正常狀態


於是 $PATH 有用了, /etc/* 也可以寫入了
還有/var/cache fakeroot/home/daemon/.cache 可以用

更好的做法:

1.  在非開發期不要依賴$PATH, 建造後全部的執行檔參照都要是絕對路徑
    這有時候很難達成, 因為很難確定其他依賴會怎麼呼叫$PATH中的程式

2.  這也包含了不要依賴/usr/bin/env, 而/bin/sh與system(3)的狀況就比較特別
    也不能再依賴which

3.  並且把/var/cache/enve/{python-pyvenv,ruby/rubies,ruby/venvs}
    移到/nix/store內, 這應該是容易辦到的


[1] https://github.com/NixOS/nixpkgs/pull/12474


# 用nix建造

1. 真實化依賴的nix語句, 包含建造期依賴與執行期依賴
2. 建造自己, 這可能只是普通的複製, 並且建立檔案內容含有路徑指向那些執行期依賴的store
3. 如果有依賴是參照$PATH的, 建立連結到bin, 這可以用buildEnv搞定
4. 如果是可部署服務, 複製與建立部署設定檔到$out/etc
5. 得到作為結果的nix-store
6. 如果是可部署服務, pm可以直接對這個store作部署

樹狀圖如下:

srv Deployable
(buildEnv)
    |
    |- [s] applicationBuild (Copy)
    |  |
    |  |- [s] runtime dependencies
    |  |- /share/dependencies
    |
    |- /etc (Deployment config)
    |- /bin/srv1.enve      (use abspath in all the file)
    |- /etc/profile.enve   (user login shell env)
    |- [s] enve
    |- [E][s] ENV runtime dependencies
    |- [E][s] management tools


pm Deployable
(buildEnv)
    |
    |- [s] srv Deployables
    |- /bin/srv1.enve
    |- /etc/srv/* (link from srv Deployable, or not necessary do that)
    |- /etc/secret/*
    |-  /etc/service.cfg
    |- /etc/passwd (opt)
    |- /etc/profile.enve
    |- [E][s] pm
    |- [E][s] enve (maybe?)
    |- [E][s] management tools


pm Deployable 是一個可以熱部署, 或是可自我部署的一個目標


# pm Deployable 熱部署的方式

### 偵測變動的服務

做法很簡單, 只要掃描服務所在的nix-closure有沒有變動就行了

1. 確定nix-closure與原本不一樣之後
2. 如果只有/etc設定檔跟原本不一樣, pm reload $srv
3. 如果/bin內的內容也不一樣了, pm restart $srv
4. 對於依賴改變的情形則比較複雜, 通常reload能解決, 但不一定
5. pm本身所在的nix-closure發生了變動, pm restart self

在確定要變更範圍之前, 可能還要進行一些rebind或是relink的動作, 這很簡單
主要就是把/etc的某些內容(或是所謂的global內容), rebind/relink到fakeroot
例如說/var/lib/$srv或是/etc/$srv或是/var/fs/$fsID


### 熱部署

含有pm的fakeroot會有一個/var/pm/closure的檔案, 只要這個檔案發生變動就會進行熱部署
因此整體部署的方式也很簡單

0. 選擇要部署的版本, 通常是在git中的某個commit
1-1. 從git版本庫簽出後在stage端進行建造測試
1-2. 如果已經在ci建造測試過了, 那就不需要了
2. 用nix-copy-closure上傳pm Deployable到目標機器(可能是虛擬的sshd)
3. 上傳成功後寫入/var/pm/closure
4. 自動化熱部署就會啟動了
5. 觀看log來確認部署與測試成功完成


也就是說理想上在同一平台下 git commit 跟 nix closure 應該要是一對一的關係




### 以enve來建造的方式

enve與nix的關係, 事實上enve-shell有點像nix-shell
1. 產生一個nix-store
2. 並且清空環境變數後進入bash, 很少變數是繼承自原本的環境

差別在於enve設定上比較簡單, 而且對於環境操作的功能很強
如果說nix封裝的是軟體包, enve是在nix的基礎上多封裝了執行環境
這也包含了一些不在nix-store裡面的例如機密檔案

enve也因此用來封裝建造環境與設定, 這點跟nix的功能是一樣的
但是不需要nix-script也能表達一個專案的建造過程與環境依賴
與nix一樣, 可以把建造結果放在外面或是nix-store都可以

nix可以利用enve建立執行環境, 所以nix跟enve要如何解呢:
nix無法直接使用enve, 只有enve才可以使用enve

今天假設A.enve依賴B.enve
建造A.enve前先執行 B.enve build-nix
會產出一個nix-store內含有B的建造結果並且附上B環境的rcfile
接下來才建造A.enve本體, 以B的nix-store作為輸入
最後產出一個nix-store內含有A與B的建造結果並且附上A與B環境的rcfile

rcfile可以被patch到每一個/bin的程式之中, 這樣可以保證執行rcfile中的程式一定會被鎖定
我把這個技術叫做Configure/Environment Binding
這讓被綁定的軟體總是執行在特定的環境與設定中, 只有少數的設定可以從外部接收或動態更改

要綁定的東西有下列:
Dependencies
Environment
Configuration
Resource
Security

不綁定的東西如下:
DynamicResource         但這個東西可能不存在, 因為會透過HA機制來路由
DynamicConfiguration    這個東西可能也只有少部分, 因為可以透過部署本身來做configure


因此enve-build就是一個利用nix將軟體或環境做封裝與綁定的工具, 並且留下一個統一的呼叫接口
所以enve-build跟nix-build一樣都是產生一個nix-store
enve-shell跟nix-shell一樣都是進入那個nix-store的那個shell

如果真的要說差別enve是基於functional shell-script的
而nix則是混雜functional nix-script和shell-script

enve的架構更簡單,概念更純粹,範疇更廣泛
nix負責是把副作用降到零, 並提供強大的團體建造

目前的想法是把enve與nix深層綁定, 但是仍然在概念上權責分層
以防有一天nix的介面大幅更改



{ stdenv, enve }:
let
    enve_profile = /xx/ooo/enve.ini;
    requires = [];
    buildDeps = [];
    env_pkgs = [];
    app = pkgs.runCommand "enveBuildApp" {
        xxxxx = enve;
        xxx = [ (import /nix/store/xd4d95w68z45czjwrx210aw1mxg6lnm8-dummy.drv) ];
    } ''
        mkdir $out
        mkdir $out/share
        touch /share/deps
        echo "${enve}" >> /share/deps

        ${enve}/enve -f $enve_profile -c build.out=$out build-nix-internal
        ln -s /nix/store/5zybyx1h1d74qzavlfpaqcxdzkl3j0w4-dummy/bin/bash $out/x
    ''
in
    pkgs.buildEnv {
        name = "${PRJ_NAME:-}${PRJ_NAME:+-}env";
        paths = with pkgs; [
            app
            $env_pkgs
        ];
        postBuild = ''
            mkdir $out
            mkdir $out/bin
            cat "${enve_profile}" > /main.rcfile
            mkdir $out/etc
            cat "${enve_profile}" > /profile.rcfile

            mkdir $out/share
            touch /share/deps
            echo "${enve}" >> /share/deps

        ''
    }





# DevOps整合

我們來看看最後整合了什麼
1.  Container
2.  Continuous Delivery / Autodeploy / Orchestration? (Non-cluster)
    (Rolling Update)
    (Service Scalability)
    (Self-healing)
3.  Automatic Build And Test
4.  Continuous Integration
5.  Dependencies/Environment/Configuration Management
6.  Environment Encapsulation
7.  Resource Provision
    (Domain Name)
    (Storage)
8.  Flow-based Version Control

雖然整體的管理功能比較弱, 但是對於中小企業來說, 這樣剛好可以降低管理負擔



上列大部分的功能都只是概念上, 和實際工具不一定有關係
甚是可以說是一種方法

來看看他們彼此之間的關係圖, 這並不是組件上的關係圖
而是功能上的關係圖

Dependencies Management
    ^
    |
Environment Encapsulation
    ^
    |
Automatic Build And Test
    ^
    |
Flow-based Version Control
    ^
    |
Continuous Integration -> Container     -> Resource Provision
    ^
    |
Continuous Delivery    -> Configuration Management


這其中做得最好的無疑是 Continuous Integration 與 Configuration Management
超越2018年的當代科技
因為我們維持了產品的整體一致性

產品做為多個服務的集合, 並且與配置和環境整合, 只留下最後因機器而異的部分, 等待最後耦合.
這個整體, 會座落在一個版本庫中, 每個提交就代表一個產品整體的快照.
這個產品快照可以被獨立測試, 測試通過之後可以被獨立發佈.
比較不同版本的產品也非常快, 將產品中的各個服務以及不同環境機器做排列組合也很快.
再配合回歸測試, 除錯將會更容易.
由於產品的開發, 測試, 發佈個週期的環境與依賴一致, 發佈後產品整體的穩定性將會極高.
發佈的速度與難度也會因為上列因素再加上自動化大大的減少.
每天可以最多做出上百次的發佈, 即時任何意外也可以隨時回滾, 回滾的穩定性也會非常高.


# RCD 唯一的要求

1.  目標機器有基於x86_64且與posix相容的內核
2.  一開始建立部署時需要一點點root權限


'


chroot_add_mount() {
    if $MOUNT_CMD "$@"; then
        CHROOT_ACTIVE_MOUNTS=("$2" "${CHROOT_ACTIVE_MOUNTS[@]}")
    else
        echo "mount failed at $2" >&2
    fi
}

CHROOT_ACTIVE_MOUNTS=()

pre_unshare_setup() {
    MOUNT_CMD=${MOUNT_CMD:-mount}
    # chroot_add_mount udev "$1/dev" -t devtmpfs -o mode=0755,nosuid

}

chroot_setup() {
    MOUNT_CMD=${MOUNT_CMD:-mount}

    # [[ $(trap -p EXIT) ]] && die '(BUG): attempting to overwrite existing EXIT trap'
    # trap 'chroot_teardown' EXIT

    for name in null zero full random urandom kmsg tty ptmx fuse; do
        cp -a "/dev/$name" "$1/dev"
    done
    for name in fd stdin stdout stderr; do
        cp -a "/dev/$name" "$1/dev"
    done
    for name in tty vcs vcsa; do
        cp -a /dev/${name}{1,2,3,4,5,6} "$1/dev"
    done


    chroot_add_mount proc "$1/proc" -t proc -o nosuid,noexec,nodev &&
    chroot_add_mount sys "$1/sys" -t sysfs -o nosuid,noexec,nodev &&
    chroot_add_mount none "$1/sys/fs/cgroup" -t cgroup2 &&
    mkdir -p $1/dev/{pts,shm} &&
    chroot_add_mount devpts "$1/dev/pts" -t devpts -o mode=0620,gid=5,nosuid,noexec &&
    chroot_add_mount shm "$1/dev/shm" -t tmpfs -o mode=1777,nosuid,nodev &&
    chroot_add_mount run "$1/run" -t tmpfs -o nosuid,nodev,mode=0755 &&
    chroot_add_mount tmp "$1/tmp" -t tmpfs -o mode=1777,strictatime,nodev,nosuid
    chroot_add_mount /bin "$1/bin" --bind -o ro
    chroot_add_mount /lib "$1/lib" --bind -o ro
    chroot_add_mount /lib64 "$1/lib64" --bind -o ro
    # chroot_add_mount /usr/lib "$1/usr/lib" --bind -o ro
    chroot_add_mount /usr/lib64 "$1/usr/lib64" --bind -o ro
    chroot_add_mount /usr/share "$1/usr/share" --bind -o ro
    mkdir "$1/etc/pam.d"
    chroot_add_mount /etc/pam.d "$1/etc/pam.d" --bind -o ro
    # mkdir -p "$1/usr/share/terminfo"
    # chroot_add_mount /usr/share/terminfo "$1/usr/share/terminfo" --bind -o ro
    # mkdir -p "$1/usr/share/bashdb"
    # chroot_add_mount /usr/share/bashdb "$1/usr/share/bashdb" --bind -o ro
}


chroot_teardown() {
    umount "${CHROOT_ACTIVE_MOUNTS[@]}"
    unset CHROOT_ACTIVE_MOUNTS
}

passwd_source='root:x:0:0::/root:/bin/bash
user1:x:1000:1000::/home/user1:/bin/bash
'
shadow_source='root::17737::::::
user1:!:17737:0:99999:7:::
'
group_source='root:x:0:root
user1:x:1000:
'
gshadow_source='root:::root
user1:!::
'

host_conf_source='
# Resolver configuration file.
# See host.conf(5) for details.

multi on
'

hosts_source='
# Static table lookup for hostnames.
# See hosts(5) for details.
'
issue_source='Arch Linux \r (\l)
'
motd_source=''

nsswitch_conf_source='
# Name Service Switch configuration file.
# See nsswitch.conf(5) for details.

passwd: files mymachines systemd
group: files mymachines systemd
shadow: files

publickey: files

hosts: files mymachines myhostname resolve [!UNAVAIL=return] dns
networks: files

protocols: files
services: files
ethers: files
rpc: files

netgroup: files
'

resolv_conf_source='
# Resolver configuration file.
# See resolv.conf(5) for details.
'

securetty_source='
# File which lists terminals from which root can log in.
# See securetty(5) for details.

console
tty1
tty2
tty3
tty4
tty5
tty6
ttyS0
hvc0
'

shells_source='
# Pathnames of valid login shells.
# See shells(5) for details.

/bin/sh
/bin/bash
'

profile_source='echo X >&2'


normalize() {
    echo "$1" | tr '.' '_'
}


package() {
    cd "$CHROOT"

    # setup root filesystem
    for d in boot dev etc home mnt usr var opt srv/http run; do
        install -d -m755 $d
    done
    install -d -m555 proc
    install -d -m555 sys
    install -d -m0750 root
    install -d -m1777 tmp


    # setup /etc and /usr/share/factory/etc
    for f in group host.conf hosts issue motd nsswitch.conf \
            passwd resolv.conf securetty shells profile; do
        # install -m644 "$srcdir"/$f etc/
        echo "$(eval echo "\"\$$(normalize ${f})_source\"")" > etc/$f
        chmod 644 etc/$f
    done
    ln -s ../proc/self/mounts etc/mtab
    for f in gshadow shadow; do
        # install -m600 "$srcdir"/$f etc/
        echo "$(eval echo "\"\$$(normalize ${f})_source\"")" > etc/$f
        chmod 600 etc/$f
    done

    # setup /var
    for d in cache local opt log/old lib/misc empty; do
        install -d -m755 var/$d
    done
    install -d -m1777 var/{tmp,spool/mail}

    # allow setgid games (gid 50) to write scores
    # install -d -m775 -g 50 var/games
    # ln -s spool/mail var/mail
    ln -s ../run var/run
    ln -s ../run/lock var/lock

    # setup /usr hierarchy
    for d in bin include lib share/misc src; do
        install -d -m755 usr/$d
    done
    for d in {1..8}; do
        install -d -m755 usr/share/man/man$d
    done

    # add lib symlinks
    ln -s usr/lib lib
    CARCH=x86_64
    [[ $CARCH = 'x86_64' ]] && {
        ln -s usr/lib lib64
        ln -s lib usr/lib64
    }

    # add bin symlinks
    ln -s usr/bin bin
    ln -s usr/bin sbin
    ln -s bin usr/sbin
    cd -
}


mkchroot() {
    mkdir -p "$CHROOT"
    package
    # MOUNT_CMD=mount chroot_setup "$CHROOT"
}



delchroot() {
    CHROOT=$HOME/chroot
    umount -l "$CHROOT/proc" || true
    umount --recursive "$CHROOT/sys" || true
    umount --recursive "$CHROOT/dev" || true
    # umount "$CHROOT/dev/pts"
    # umount "$CHROOT/dev/shm"
    umount "$CHROOT/run" || true
    umount "$CHROOT/tmp" || true
    umount -l "$CHROOT/bin" || true
    umount -l "$CHROOT/lib" || true
    umount -l "$CHROOT/lib64" || true
    umount -l "$CHROOT/usr/lib" || true
    umount -l "$CHROOT/usr/lib64" || true
    umount -l "$CHROOT/usr/share" || true
    umount -l "$CHROOT/etc/pam.d" || true

    # umount -l "$CHROOT/etc" || true
    # umount -l "$CHROOT/usr/share/terminfo" || true
    # umount --recursive "$CHROOT" || true
    rm -rf "$CHROOT"
}






enter() {
    nsenter --ipc --uts --cgroup --net --user --pid --mount --target $pid "$@"
}

dochroot() {
    setpriv -dd
    #--mount-proc=$CHROOT/proc

    # pre_unshare_setup "$CHROOT"


    # Reaps adopted child processes.
    # Executes subprocesses.
    # Waits until all subprocesses are terminated before terminating itself, but with a maximum timeout.

    unshare --ipc --uts --cgroup --net --user --pid --mount --fork --kill-child \
        /bin/bash -c '
function cleanup()
{
    local pids=`jobs -p`
    echo pid-b $(jobs -p)
    if [[ "$pids" != "" ]]; then
        kill $pids >/dev/null 2>/dev/null
    fi
    echo pid-c $(jobs -p)
    wait $(jobs -p)
    echo pid-d $(jobs -p)
}

trap cleanup EXIT TERM
sleep 1000 &
echo "pid-a $(jobs -p)"
wait $(jobs -p)
' &


    sleep 1
    pid=$(ps | grep sleep | awk '{ print $1 }')
    echo "pid: $pid"
    printf "0:0:10000\n" > /etc/subuid
    printf "0:0:10000\n" > /etc/subgid
    newuidmap $pid 0 0 1  1 3001 3000 || echo "newuidmap $pid faild"
    newgidmap $pid 0 0 1  1 3001 3000 || echo "newgidmap $pid faild"

    # newuidmap $pid  1 3001 3000 || echo "newuidmap $pid faild"
    # newgidmap $pid  1 3001 3000 || echo "newgidmap $pid faild"

    # nsenter --ipc --uts --cgroup --net --user --pid --mount --target $pid chmod 755 "$CHROOT/sys/fs/cgroup"

    MOUNT_CMD="enter mount" chroot_setup "$CHROOT"

    # Note however, that mounting block-based filesystems can be done only
    #    by a process that holds CAP_SYS_ADMIN in the initial user namespace.

    export TERM=xterm-color
    setpriv --bounding-set -all,+sys_chroot \
        nsenter --ipc --uts --cgroup --net --user --pid --mount --target $pid chroot "$CHROOT" /bin/bash

    # enter chroot "$CHROOT" runuser -u user1 -- /bin/bash


    # SHELL=/usr/bin/bash unshare --user --map-root-user --pid --mount --fork --kill-child --mount-proc=$CHROOT/proc \
    # bash -c "cat $CHROOT/proc/self/setgroups; printf 'allow' > $CHROOT/proc/self/setgroups; chroot $CHROOT"
}

main() {

    # pid=$({ps | grep unshare | awk '{ print $1 }';} || true)
    # kill $pid || true

    if pid=$(ps | grep unshare | awk '{ print $1 }'); then
        kill $pid
    fi
    delchroot
    mkchroot
    dochroot
}

function join_by { local IFS="$1"; shift; echo "$*"; }

minicap() {
    if [ -z "${MINICAP:-}" ]; then
        caps=()
        caps=( ${caps[@]} -all)
        caps=( ${caps[@]} +sys_admin)
        caps=( ${caps[@]} +sys_chroot)
        caps=( ${caps[@]} +setpcap)
        caps=( ${caps[@]} +setuid)
        caps=( ${caps[@]} +setgid)
        caps=( ${caps[@]} +mknod)
        caps=( ${caps[@]} +chown)

        MINICAP=1 setpriv --bounding-set $(join_by ',' "${caps[@]}") $0
    else
        main
    fi
}

# mkchroot2() {
#     mkdir -p "$CHROOT"
#     package
#     MOUNT_CMD=mount chroot_setup "$CHROOT"
# }

# CHROOT=${1:-$HOME/chroot}
# if [ -n "${1:-}" ]; then
#   shift
# fi
# mkchroot2
# minicap
# main


mksystemdsrv() {
    contname="$(basename $1)"

    cat > "/run/systemd/root-${contname}.service" << EOF
        [Unit]
        Description=${contname} Namespace Daemon
        Before=cont-${contname}.service
        StopWhenUnneeded=true

        [Service]
        ExecStart=$0 serveroot $1
EOF

    cat > "/run/systemd/cont-${contname}.service" << EOF
        [Unit]
        Description=${contname} Container Daemon
        Requires=root-${contname}.service

        [Service]
        ExecStart=$0 startns $1
        ExecReload=/bin/kill -HUP $MAINPID
        KillMode=process
        Restart=always
EOF


}

if [ "$#" -gt 0 ]; then
    case $1 in
        serveroot)
                shift
                serverootdir "$@"
            ;;
        delayinit)
                shift
                delayinit "$@"
            ;;
        startns)
                shift
                startns "$@"
            ;;
        host)
                shift
                selfhost "$@"
            ;;
        generate)
                shift
                mksystemdsrv "$@"
            ;;
        *)
                error "command not found: $1"
            ;;
    esac
fi
